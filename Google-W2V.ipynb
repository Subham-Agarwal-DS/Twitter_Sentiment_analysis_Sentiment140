{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17a801d8",
   "metadata": {
    "id": "17a801d8"
   },
   "outputs": [],
   "source": [
    "# utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd691137",
   "metadata": {
    "id": "dd691137",
    "outputId": "a2c97dee-60b4-41dd-86cb-2915cd6c3d6f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love not wait se admin best server ever hapy</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recruiter comunity server sharepoint dev gig a...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not paying god seat watch miley gues bc switch...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ah excited pushi home okay aw hapy right</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>col pic amp username ahah whats up</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545656</th>\n",
       "      <td>going go big house borow si guitar play maybe ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545657</th>\n",
       "      <td>dish sen prepare website would afraid recomend...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545658</th>\n",
       "      <td>birthday</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545659</th>\n",
       "      <td>hury not think jon kate</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545660</th>\n",
       "      <td>ltlti not know cud dat phone til wowmy life co...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1545661 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  target\n",
       "0             love not wait se admin best server ever hapy     1.0\n",
       "1        recruiter comunity server sharepoint dev gig a...     1.0\n",
       "2        not paying god seat watch miley gues bc switch...     0.0\n",
       "3                 ah excited pushi home okay aw hapy right     1.0\n",
       "4                       col pic amp username ahah whats up     1.0\n",
       "...                                                    ...     ...\n",
       "1545656  going go big house borow si guitar play maybe ...     1.0\n",
       "1545657  dish sen prepare website would afraid recomend...     1.0\n",
       "1545658                                           birthday     1.0\n",
       "1545659                            hury not think jon kate     1.0\n",
       "1545660  ltlti not know cud dat phone til wowmy life co...     1.0\n",
       "\n",
       "[1545661 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('twitter.cleaned_no_hashtags.csv')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01b6afc3",
   "metadata": {
    "id": "01b6afc3",
    "outputId": "aad6b175-aabe-481d-bd30-89444d295f72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1545661 entries, 0 to 1545660\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count    Dtype  \n",
      "---  ------  --------------    -----  \n",
      " 0   text    1545661 non-null  object \n",
      " 1   target  1545661 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 23.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8352074",
   "metadata": {
    "id": "e8352074"
   },
   "source": [
    "### Analyzing sequences to use Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb6dbfb",
   "metadata": {
    "id": "6fb6dbfb",
    "outputId": "5523dc08-25ee-4493-e801-8236e0324fc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = max(df['text'].apply(lambda x: len(x.split())))\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f41380f3",
   "metadata": {
    "id": "f41380f3",
    "outputId": "6be8e148-4aad-4559-d1aa-ca18820c0914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding length is 36\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length = (int(val/4)+1)*4\n",
    "print(f'Padding length is {max_sequence_length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc6de5f",
   "metadata": {
    "id": "abc6de5f",
    "variables": {
     "max_sequence_length": "36",
     "val": "34"
    }
   },
   "source": [
    "#### Max sequence length is {{val}}, assume {{max_sequence_length}} to keep sufficient padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75f338ee",
   "metadata": {
    "id": "75f338ee"
   },
   "outputs": [],
   "source": [
    "# data = [alp.split() for alp in df['text']]\n",
    "\n",
    "# # corpus_text=[elem for elem in alp for alp in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0cdf7bb",
   "metadata": {
    "id": "a0cdf7bb"
   },
   "outputs": [],
   "source": [
    "model_name = r'/Users/subhagr/Desktop/My files/GoogleNews-vectors-negative300.bin'\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(model_name, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "352490cd",
   "metadata": {
    "id": "352490cd"
   },
   "outputs": [],
   "source": [
    "word = 'king'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ff60b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000\n"
     ]
    }
   ],
   "source": [
    "word_list = model.index_to_key\n",
    "\n",
    "print(len(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "962ecbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.key_to_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ccb7275",
   "metadata": {
    "id": "7ccb7275",
    "outputId": "101553e3-0648-43e0-e929-0c3c06bb3622"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kings', 0.7138046622276306),\n",
       " ('queen', 0.6510956287384033),\n",
       " ('monarch', 0.6413194537162781),\n",
       " ('crown_prince', 0.6204220056533813),\n",
       " ('prince', 0.6159993410110474),\n",
       " ('sultan', 0.5864824056625366),\n",
       " ('ruler', 0.5797566771507263),\n",
       " ('princes', 0.5646552443504333),\n",
       " ('Prince_Paras', 0.5432944297790527),\n",
       " ('throne', 0.5422104597091675)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "364a7b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>', 'in', 'for', 'that', 'is', 'on', '##', 'The', 'with', 'said']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd21483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_checker(word):\n",
    "    for letter in word:\n",
    "        if letter not in 'abcdefghijklmnopqrstuvwxyz':\n",
    "            return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88d10db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [word for word in word_list if word_checker(word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97df1391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "631815"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09ebef50",
   "metadata": {
    "id": "09ebef50",
    "outputId": "56015e93-5954-41e3-a84d-6152b7194228"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['list'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8edf4920",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = model['word'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fae837",
   "metadata": {
    "id": "62fae837"
   },
   "source": [
    "## Splitting, vectorising, and flattening the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9ad23bf",
   "metadata": {
    "id": "e9ad23bf",
    "outputId": "b88d1779-35cc-4159-a379-9cc1b66f0c1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    7744\n",
       "0.0    7713\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minidf = df.sample(frac=0.01)\n",
    "minidf['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2d65bf",
   "metadata": {
    "id": "dc2d65bf"
   },
   "source": [
    "Balanced!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcf9a51b",
   "metadata": {
    "id": "dcf9a51b"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(minidf['text'].apply(lambda x: x.split()), \n",
    "                                    minidf['target'].values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb5237ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is passed with a sequence- list of words and returns the vector\n",
    "# If normal = True, vector will be averaged over all words, otherwise summed\n",
    "\n",
    "def get_embedding(sequence, normal = False):\n",
    "    vec = np.zeros((vector_size), dtype= float)\n",
    "    count= 0\n",
    "    for word in sequence:\n",
    "        if word in word_list:\n",
    "            vec += model[word]\n",
    "            count +=1\n",
    "#             print(word)\n",
    "    global glob_counter\n",
    "    glob_counter +=1\n",
    "    if(glob_counter%100 ==0):print(glob_counter)\n",
    "        \n",
    "    if(normal): return vec/(max(count,1))\n",
    "    else: return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76809b4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n"
     ]
    }
   ],
   "source": [
    "glob_counter = 0\n",
    "X_train_embed = np.array([get_embedding(sequ) for sequ in X_train])\n",
    "X_test_embed = np.array([get_embedding(sequ) for sequ in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "081642e3",
   "metadata": {
    "id": "081642e3",
    "outputId": "670fc9dd-378b-4b3a-ced9-8253277f9a93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12365, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cb24714",
   "metadata": {
    "id": "4cb24714",
    "outputId": "f632ed0d-69d7-407d-fba0-ab7e0856dce5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3092, 300)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_embed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47d86a7",
   "metadata": {},
   "source": [
    "## Using w2v embeddings on models to check performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1434802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc = LinearSVC(C = 0.1)\n",
    "svc.fit(X_train_embed, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2c3d8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.71      0.71      1515\n",
      "         1.0       0.72      0.73      0.73      1577\n",
      "\n",
      "    accuracy                           0.72      3092\n",
      "   macro avg       0.72      0.72      0.72      3092\n",
      "weighted avg       0.72      0.72      0.72      3092\n",
      "\n",
      "[[1070  445]\n",
      " [ 420 1157]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = svc.predict(X_test_embed)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81a221e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebbddc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc78e840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C=1)\n",
    "lr.fit(X_train_embed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70c69211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.71      0.72      1515\n",
      "         1.0       0.73      0.73      0.73      1577\n",
      "\n",
      "    accuracy                           0.72      3092\n",
      "   macro avg       0.72      0.72      0.72      3092\n",
      "weighted avg       0.72      0.72      0.72      3092\n",
      "\n",
      "[[1078  437]\n",
      " [ 420 1157]]\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = lr.predict(X_test_embed)\n",
    "print(classification_report(y_test, y_pred2))\n",
    "print(confusion_matrix(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3126002b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792a8fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab28270e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_embed,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ddf1a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.67      0.66      1515\n",
      "         1.0       0.67      0.65      0.66      1577\n",
      "\n",
      "    accuracy                           0.66      3092\n",
      "   macro avg       0.66      0.66      0.66      3092\n",
      "weighted avg       0.66      0.66      0.66      3092\n",
      "\n",
      "[[1010  505]\n",
      " [ 552 1025]]\n"
     ]
    }
   ],
   "source": [
    "y_pred3 = bnb.predict(X_test_embed)\n",
    "print(classification_report(y_test, y_pred3))\n",
    "print(confusion_matrix(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c917c94",
   "metadata": {},
   "source": [
    "## Using \"better\" methods for Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87789480",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.65658856\n",
      "Validation score: 0.688763\n",
      "Iteration 2, loss = 0.57020640\n",
      "Validation score: 0.711399\n",
      "Iteration 3, loss = 0.55270267\n",
      "Validation score: 0.733226\n",
      "Iteration 4, loss = 0.55066642\n",
      "Validation score: 0.722716\n",
      "Iteration 5, loss = 0.54888045\n",
      "Validation score: 0.730800\n",
      "Iteration 6, loss = 0.54888306\n",
      "Validation score: 0.725141\n",
      "Iteration 7, loss = 0.54785144\n",
      "Validation score: 0.715441\n",
      "Iteration 8, loss = 0.54547799\n",
      "Validation score: 0.729184\n",
      "Iteration 9, loss = 0.54403480\n",
      "Validation score: 0.730800\n",
      "Iteration 10, loss = 0.54719617\n",
      "Validation score: 0.718674\n",
      "Iteration 11, loss = 0.54308648\n",
      "Validation score: 0.717057\n",
      "Iteration 12, loss = 0.54234802\n",
      "Validation score: 0.717057\n",
      "Iteration 13, loss = 0.54058466\n",
      "Validation score: 0.728375\n",
      "Iteration 14, loss = 0.54326757\n",
      "Validation score: 0.724333\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='identity', early_stopping=True,\n",
       "              hidden_layer_sizes=(300, 10, 10, 1), max_iter=100, verbose=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(300,10,10,1),activation='identity',solver='adam',\n",
    "    alpha=0.0001, batch_size='auto',learning_rate='constant',learning_rate_init=0.001,power_t=0.5,\n",
    "    max_iter=100,shuffle=True,random_state=None,tol=0.0001,verbose=True,warm_start=False,momentum=0.9,\n",
    "    nesterovs_momentum=True, early_stopping=True,validation_fraction=0.1,beta_1=0.9,beta_2=0.999,\n",
    "    epsilon=1e-08,n_iter_no_change=10,max_fun=15000)\n",
    "mlp.fit(X_train_embed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01358c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.71      0.72      1515\n",
      "         1.0       0.72      0.74      0.73      1577\n",
      "\n",
      "    accuracy                           0.72      3092\n",
      "   macro avg       0.72      0.72      0.72      3092\n",
      "weighted avg       0.72      0.72      0.72      3092\n",
      "\n",
      "[[1073  442]\n",
      " [ 413 1164]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp.predict(X_test_embed)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e94fb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
